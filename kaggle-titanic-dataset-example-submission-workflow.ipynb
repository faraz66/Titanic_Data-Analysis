{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Can we predict who would've survived the Titanic?\n\n### This notebook goes through a basic exploratory data analysis of the Kaggle Titanic dataset with Python\n\nAlthough this notebook works towards creating a Kaggle submission, it should not be taken as exhaustive list of things to do with a dataset. It has been setup as an introduction to get you started with exploratory data analysis (EDA).\n\nThere are challenges and extensions listed throughout. I encourage you to take the foundations here and build upon them.\n\nKeep learning,\n\nFaraz Shaikh"},{"metadata":{},"cell_type":"markdown","source":"## Step 0: Why EDA?\n\n\nNot all data comes in a neat little package ready to be modelled by the latest and greatest machine learning models.\n\nMost of the time, you'll get a dataset you don't know much about. So before you can make any solid predictions, you'll to find out more.\n\nThis is where EDA comes in.\n\nThe main thing to remember is the first word. Exploratory. You're trying to figure out more about the data so you can build a model the best way you can.\n\nYou'll usually do this when you first look at a dataset but it'll continually happen as you learn more. EDA is an iterative process. There's no one way to do it either. It'll vary with each new dataset but there are some things you'll find yourself doing more often, we'll talk about those in this notebook and in a future blog post.\n"},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Download the data\n\nYou can download the data for this notebook here: https://www.kaggle.com/c/titanic/data"},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Work through the notebook\n    \nFirst we will import all the relevant dependencies we need.\n\nIf you don't have any of these, the notebook will throw an error. The error will likely tell you what you don't have. Then you'll have to install it.\n\nYou can usually figure out how to install it by Googling: \"how to install [the thing you don't have]\".\n\n**PS** If you have any questions, feedback, advice or bug fixes, please let me know."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading in the data\n\nAfter we've downloaded the data, we need to get it into the notebook.\n\nI've stored my downloaded data in a file called `data`."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import train & test data \ntrain = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\ngender_submission = pd.read_csv('data/gender_submission.csv') # example of what a submission should look like","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# View the training data\ntrain.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.Age.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# View the test data (same columns as the training data)\ntest.head() # head = view first 5 lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# View the example submisison dataframe\ngender_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Descriptions\n\n**Survival:** 0 = No, 1 = Yes\n\n**pclass (Ticket class):** 1 = 1st, 2 = 2nd, 3 = 3rd\n\n**sex:** Sex\n\n**Age:** Age in years\n\n**sibsp:** number of siblings/spouses aboard the Titanic\n\n**parch:** number of parents/children aboard the Titanic\n\n**ticket:** Ticket number\n\n**fare:** Passenger fare\n\n**cabin:** Cabin number\n\n**embarked:** Port of Embarkation, C = Cherbourg, Q = Queenstown, S = Southampton"},{"metadata":{"trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What missing values are there?\n\nWhere are the holes in our data?\n\nThese are rows which are missing a value or have NaN instead of something like the rest of the column."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot graphic of missing values\nmissingno.matrix(train, figsize = (30,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok we can clearly see some missing values here. Especially in the cabin column.\n\nIt's important to visualise missing values early so you know where the major holes are in your dataset.\n\nKnowing this informaiton will help with your EDA and figuring out what kind of data cleaning and preprocessing is needed."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Alternatively, you can see the number of missing values like this\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## To perform our data analysis, let's create two new dataframes\n\nWe'll create one for exploring discretised continuous variables (continuous variables which have been sorted into some kind of category) and another for exploring continuous variables."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_bin = pd.DataFrame() # for discretised continuous variables\ndf_con = pd.DataFrame() # for continuous variables","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What datatypes are in the dataframe?\n\nAs a general rule of thumb, features with a datatype of object could be considered categorical features. And those which are floats or ints (numbers) could be considered numerical features.\n\nHowever, as we dig deeper, we might find features which are numerical may actually be categorical.\n\nThe goal for the next few steps is to figure out how best to process the data so our machine learning model can learn from it.\n\nIdeally, all the features will be encoded into a numerical value of some kind. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Different data types in the dataset\ntrain.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's explore each of these features individually\nWe'll go through each column iteratively and see which ones to use in our first models.\nSome may need more preprocessing than others to get ready."},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Feature: Survived\n\nDescription: Whether the passenger survived or not.\n    \nKey: 0 = did not survive, 1 = survived\n    \nThis is the variable we want our machine learning model to predict based off all the others."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many people survived?\nfig = plt.figure(figsize=(20,1))\nsns.countplot(y='Survived', data=train);\nprint(train.Survived.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's add this to our subset dataframes\ndf_bin['Survived'] = train['Survived']\ndf_con['Survived'] = train['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_bin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_con.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature: Pclass\n\nDescription: The ticket class of the passenger.\n    \nKey: 1 = 1st, 2 = 2nd, 3 = 3rd"},{"metadata":{},"cell_type":"markdown","source":"#### Let's plot the distribution\nWe will look at the distribution of each feature first if we can to understand what kind of spread there is across the dataset.\n\nFor example, if there are values which are completely outside of the distribution, we may not want to include them in our model."},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.distplot(train.Pclass)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see with this feature, the values are numerical (1, 2 and 3) but they are categories.\n\nHow do we know this? Because a passenger in Class 3 doesn't necessarily equal a passenger in Class 2 + a passenger in Class 1."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing variables does Pclass have?\ntrain.Pclass.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are no missing values in Pclass, let's add it to our sub dataframes."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_bin['Pclass'] = train['Pclass']\ndf_con['Pclass'] = train['Pclass']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature: Name\n    \nDescription: The name of the passenger."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many different names are there?\ntrain.Name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Every row has a unique name. This is equivalent to the passenger ID. But name could be used differently.\n\nCan you think of ways you could reduce the number of different names? Or create new features out of the names?\n\n**Note:** Because of so many different names and to keep this EDA fast, we won't move forward using the name variable."},{"metadata":{},"cell_type":"markdown","source":"### Feature: Sex\n\nDescription: The sex of the passenger (male or female)."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's view the distribution of Sex\nplt.figure(figsize=(20, 5))\nsns.countplot(y=\"Sex\", data=train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Are there any missing values in the Sex column?\ntrain.Sex.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since this is already binary variable (male or female), let's add it straight to our subset dataframes."},{"metadata":{"trusted":false},"cell_type":"code","source":"train.Sex.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# add Sex to the subset dataframes\ndf_bin['Sex'] = train['Sex']\ndf_bin['Sex'] = np.where(df_bin['Sex'] == 'female', 1, 0) # change sex to 0 for male and 1 for female\n\ndf_con['Sex'] = train['Sex']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# How does the Sex variable look compared to Survival?\n# We can see this because they're both binarys.\nfig = plt.figure(figsize=(10, 10))\nsns.distplot(df_bin.loc[df_bin['Survived'] == 1]['Sex'], kde_kws={'label': 'Survived'});\nsns.distplot(df_bin.loc[df_bin['Survived'] == 0]['Sex'], kde_kws={'label': 'Did not survive'});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not many people survived. But of those who did, more were female."},{"metadata":{},"cell_type":"markdown","source":"### Feature: Age\n\nDescription: The age of the passenger."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does age have?\ntrain.Age.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Out of a total 891 rows, that's almost one quarter of the dataset.\n\nWhat would you do with these missing values?\n\nCould replace them with the average age? What's the pro's and con's of doing this?\n\nOr would you get rid of them completely?\n\nWe won't answer these questions in our initial EDA but this is something we would definitely revisit at a later date.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Once the Age values have been fixed up, we can add them to our sub dataframes.\n# df_bin['Age'] = pd.cut(train['Age'], 10) # bucketed/binned into different categories\n# df_con['Age'] = train['Age'] # non-bucketed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Challenge:** How would you fill the missing variables in the `Age` column?"},{"metadata":{},"cell_type":"markdown","source":"#### Function to create count and distribution visualisations"},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_count_dist(data, bin_df, label_column, target_column, figsize=(20, 5), use_bin_df=False):\n    \"\"\"\n    Function to plot counts and distributions of a label variable and \n    target variable side by side.\n    ::param_data:: = target dataframe\n    ::param_bin_df:: = binned dataframe for countplot\n    ::param_label_column:: = binary labelled column\n    ::param_target_column:: = column you want to view counts and distributions\n    ::param_figsize:: = size of figure (width, height)\n    ::param_use_bin_df:: = whether or not to use the bin_df, default False\n    \"\"\"\n    if use_bin_df: \n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=bin_df);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={\"label\": \"Did not survive\"});\n    else:\n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=data);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={\"label\": \"Did not survive\"});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature: SibSp\n\nDescription: The number of siblings/spouses the passenger has aboard the Titanic."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does SibSp have?\ntrain.SibSp.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# What values are there?\ntrain.SibSp.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's add SibSp to our subset dataframes and view the distributions."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add SibSp to subset dataframes\ndf_bin['SibSp'] = train['SibSp']\ndf_con['SibSp'] = train['SibSp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Visualise the counts of SibSp and the distribution of the values\n# against Survived\nplot_count_dist(train, \n                bin_df=df_bin, \n                label_column='Survived', \n                target_column='SibSp', \n                figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What does the graph on the right tell us?"},{"metadata":{},"cell_type":"markdown","source":"### Feature: Parch\n\nDescription: The number of parents/children the passenger has aboard the Titanic."},{"metadata":{},"cell_type":"markdown","source":"Since this feature is similar to SibSp, we'll do a similar analysis."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does Parch have?\ntrain.Parch.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# What values are there?\ntrain.Parch.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add Parch to subset dataframes\ndf_bin['Parch'] = train['Parch']\ndf_con['Parch'] = train['Parch']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Visualise the counts of Parch and the distribution of the values\n# against Survived\nplot_count_dist(train, \n                bin_df=df_bin,\n                label_column='Survived', \n                target_column='Parch', \n                figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What does the graph on the right tell us about `Parch`?"},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_con.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature: Ticket\n\nDescription: The ticket number of the boarding passenger."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does Ticket have?\ntrain.Ticket.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many kinds of ticket are there?\nsns.countplot(y=\"Ticket\", data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That doesn't look too good, what about another way of looking at it?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many kinds of ticket are there?\ntrain.Ticket.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many unique kinds of Ticket are there?\nprint(\"There are {} unique Ticket values.\".format(len(train.Ticket.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"681 unique values is too many for now. So we won't use `Ticket` in our subset dataframes.\n\nThere may be some way to reduce this down. \n\n**Challenge:** How could you reduce the Ticket feature? Is it even possible?\n\n*Hint:* It may be similar to what you could do with Name."},{"metadata":{},"cell_type":"markdown","source":"### Feature: Fare\n\nDescription: How much the ticket cost."},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does Fare have?\ntrain.Fare.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many different values of Fare are there?\nsns.countplot(y=\"Fare\", data=train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# What kind of variable is Fare?\ntrain.Fare.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many unique kinds of Fare are there?\nprint(\"There are {} unique Fare values.\".format(len(train.Fare.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because Fare is a float (number) let's add it as it is to our continuous sub dataframe but to add it to our categorical sub dataframe, we'll cut it into bins."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add Fare to sub dataframes\ndf_con['Fare'] = train['Fare'] \ndf_bin['Fare'] = pd.cut(train['Fare'], bins=5) # discretised ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# What do our Fare bins look like?\ndf_bin.Fare.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Visualise the Fare bin counts as well as the Fare distribution versus Survived.\nplot_count_dist(data=train,\n                bin_df=df_bin,\n                label_column='Survived', \n                target_column='Fare', \n                figsize=(20,10), \n                use_bin_df=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Challenge:** How would you change the Fare bins?"},{"metadata":{},"cell_type":"markdown","source":"### Feature: Cabin\n\nDescription: The cabin number where the passenger was staying.    "},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does Cabin have?\ntrain.Cabin.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# What do the Cabin values look like?\ntrain.Cabin.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are too many missing values, we won't use Cabin for our initial models and won't add it to our sub dataframes.\n\nBut how could you modify cabin to be more usable?\n\nWhat could you do about the missing values?"},{"metadata":{},"cell_type":"markdown","source":"### Feature: Embarked\n\nDescription: The port where the passenger boarded the Titanic.\n    \nKey: C = Cherbourg, Q = Queenstown, S = Southampton"},{"metadata":{"trusted":false},"cell_type":"code","source":"# How many missing values does Embarked have?\ntrain.Embarked.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# What kind of values are in Embarked?\ntrain.Embarked.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked is a categorical variable because there are 3 categories which a passenger could have boarded on."},{"metadata":{"trusted":false},"cell_type":"code","source":"# What do the counts look like?\nsns.countplot(y='Embarked', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### How can we deal with the 2 missing values of Embarked?"},{"metadata":{},"cell_type":"markdown","source":"One option is to drop the two rows which don't have an Embarked value.\n\nAnother option would be to randomly assign a value of C, Q or S to each row.\n\nWhat are the pros and cons of each?\n\nFor now, we will remove those rows."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add Embarked to sub dataframes\ndf_bin['Embarked'] = train['Embarked']\ndf_con['Embarked'] = train['Embarked']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove Embarked rows which are missing values\nprint(len(df_con))\ndf_con = df_con.dropna(subset=['Embarked'])\ndf_bin = df_bin.dropna(subset=['Embarked'])\nprint(len(df_con))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We've removed the two rows with missing values for Embarked, now we can add Embarked to our sub dataframes."},{"metadata":{},"cell_type":"markdown","source":"## Feature Encoding\nNow we have our two sub dataframes ready. We can encode the features so they're ready to be used with our machine learning models.\n\nWe will encode our binned dataframe (`df_bin`) with one-hot encoding and our continuous dataframe (`df_con`) with the label encoding function from `sklearn`."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_bin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# One-hot encode binned variables\none_hot_cols = df_bin.columns.tolist()\none_hot_cols.remove('Survived')\ndf_bin_enc = pd.get_dummies(df_bin, columns=one_hot_cols)\n\ndf_bin_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_con.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Update:** The original version of this notebook used the `LabelEncoder()` function for encoding `df_con_enc`. However, as Tomáš pointed out, OneHotEncoder is better to use.\n    \nCheck this article for more details: https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621"},{"metadata":{"trusted":false},"cell_type":"code","source":"# One hot encode the categorical columns\ndf_embarked_one_hot = pd.get_dummies(df_con['Embarked'], \n                                     prefix='embarked')\n\ndf_sex_one_hot = pd.get_dummies(df_con['Sex'], \n                                prefix='sex')\n\ndf_plcass_one_hot = pd.get_dummies(df_con['Pclass'], \n                                   prefix='pclass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Combine the one hot encoded columns with df_con_enc\ndf_con_enc = pd.concat([df_con, \n                        df_embarked_one_hot, \n                        df_sex_one_hot, \n                        df_plcass_one_hot], axis=1)\n\n# Drop the original categorical columns (because now they've been one hot encoded)\ndf_con_enc = df_con_enc.drop(['Pclass', 'Sex', 'Embarked'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's look at df_con_enc\ndf_con_enc.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start Building Machine Learning Models\nNow our data has been manipulating and converted to numbers, we can run a series of different machine learning algorithms over it to find which yield the best results."},{"metadata":{},"cell_type":"markdown","source":"### Let's seperate the data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Seclect the dataframe we want to use first for predictions\nselected_df = df_con_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"selected_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Split the dataframe into data and labels\nX_train = selected_df.drop('Survived', axis=1) # data\ny_train = selected_df.Survived # labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Shape of the data (without labels)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Shape of the labels\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a function to fit machine learning algorithms\nSince many of the algorithms we will use are from the sklearn library, they all take similar (practically the same) inputs and produce similar outputs.\n\nTo prevent writing code multiple times, we will functionise fitting the model and returning the accuracy scores."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Function that runs the requested algorithm and returns the accuracy metrics\ndef fit_ml_algo(algo, X_train, y_train, cv):\n    \n    # One Pass\n    model = algo.fit(X_train, y_train)\n    acc = round(model.score(X_train, y_train) * 100, 2)\n    \n    # Cross Validation \n    train_pred = model_selection.cross_val_predict(algo, \n                                                  X_train, \n                                                  y_train, \n                                                  cv=cv, \n                                                  n_jobs = -1)\n    # Cross-validation accuracy metric\n    acc_cv = round(metrics.accuracy_score(y_train, train_pred) * 100, 2)\n    \n    return train_pred, acc, acc_cv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Logistic Regression\nstart_time = time.time()\ntrain_pred_log, acc_log, acc_cv_log = fit_ml_algo(LogisticRegression(), \n                                                               X_train, \n                                                               y_train, \n                                                                    10)\nlog_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_log)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_log)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=log_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbours"},{"metadata":{"trusted":false},"cell_type":"code","source":"# k-Nearest Neighbours\nstart_time = time.time()\ntrain_pred_knn, acc_knn, acc_cv_knn = fit_ml_algo(KNeighborsClassifier(), \n                                                  X_train, \n                                                  y_train, \n                                                  10)\nknn_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_knn)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_knn)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=knn_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gaussian Naive Bayes"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Gaussian Naive Bayes\nstart_time = time.time()\ntrain_pred_gaussian, acc_gaussian, acc_cv_gaussian = fit_ml_algo(GaussianNB(), \n                                                                      X_train, \n                                                                      y_train, \n                                                                           10)\ngaussian_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_gaussian)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_gaussian)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=gaussian_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Support Vector Machines (SVC)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Linear SVC\nstart_time = time.time()\ntrain_pred_svc, acc_linear_svc, acc_cv_linear_svc = fit_ml_algo(LinearSVC(),\n                                                                X_train, \n                                                                y_train, \n                                                                10)\nlinear_svc_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_linear_svc)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_linear_svc)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=linear_svc_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stochastic Gradient Descent"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Stochastic Gradient Descent\nstart_time = time.time()\ntrain_pred_sgd, acc_sgd, acc_cv_sgd = fit_ml_algo(SGDClassifier(), \n                                                  X_train, \n                                                  y_train,\n                                                  10)\nsgd_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_sgd)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_sgd)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=sgd_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Classifier\nstart_time = time.time()\ntrain_pred_dt, acc_dt, acc_cv_dt = fit_ml_algo(DecisionTreeClassifier(), \n                                                                X_train, \n                                                                y_train,\n                                                                10)\ndt_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_dt)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_dt)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=dt_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boost Trees"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Gradient Boosting Trees\nstart_time = time.time()\ntrain_pred_gbt, acc_gbt, acc_cv_gbt = fit_ml_algo(GradientBoostingClassifier(), \n                                                                       X_train, \n                                                                       y_train,\n                                                                       10)\ngbt_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_gbt)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_gbt)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=gbt_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CatBoost Algorithm\nCatBoost is a state-of-the-art open-source gradient boosting on decision trees library.\n\nIt's simple and easy to use. And is now regularly one of my go-to algorithms for any kind of machine learning task.\n\nFor more on CatBoost and the methods it uses to deal with categorical variables, check out the [CatBoost docs](https://catboost.ai/)."},{"metadata":{"trusted":false},"cell_type":"code","source":"# View the data for the CatBoost model\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# View the labels for the CatBoost model\ny_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define the categorical features for the CatBoost model\ncat_features = np.where(X_train.dtypes != np.float)[0]\ncat_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This means Catboost has picked up that all variables except `Fare` can be treated as categorical."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Use the CatBoost Pool() function to pool together the training data and categorical feature labels\ntrain_pool = Pool(X_train, \n                  y_train,\n                  cat_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# CatBoost model definition\ncatboost_model = CatBoostClassifier(iterations=1000,\n                                    custom_loss=['Accuracy'],\n                                    loss_function='Logloss')\n\n# Fit CatBoost model\ncatboost_model.fit(train_pool,\n                   plot=True)\n\n# CatBoost accuracy\nacc_catboost = round(catboost_model.score(X_train, y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform CatBoost cross-validation"},{"metadata":{"trusted":false},"cell_type":"code","source":"# How long will this take?\nstart_time = time.time()\n\n# Set params for cross-validation as same as initial model\ncv_params = catboost_model.get_params()\n\n# Run the cross-validation for 10-folds (same as the other models)\ncv_data = cv(train_pool,\n             cv_params,\n             fold_count=10,\n             plot=True)\n\n# How long did it take?\ncatboost_time = (time.time() - start_time)\n\n# CatBoost CV results save into a dataframe (cv_data), let's withdraw the maximum accuracy score\nacc_cv_catboost = round(np.max(cv_data['test-Accuracy-mean']) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Print out the CatBoost model metrics\nprint(\"---CatBoost Metrics---\")\nprint(\"Accuracy: {}\".format(acc_catboost))\nprint(\"Accuracy cross-validation 10-Fold: {}\".format(acc_cv_catboost))\nprint(\"Running Time: {}\".format(datetime.timedelta(seconds=catboost_time)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Results\nWhich model had the best cross-validation accuracy?\n\n**Note:** We care most about cross-validation metrics because the metrics we get from `.fit()` can randomly score higher than usual."},{"metadata":{},"cell_type":"markdown","source":"### Regular accuracy scores"},{"metadata":{"trusted":false},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['KNN', 'Logistic Regression', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree', 'Gradient Boosting Trees',\n              'CatBoost'],\n    'Score': [\n        acc_knn, \n        acc_log,  \n        acc_gaussian, \n        acc_sgd, \n        acc_linear_svc, \n        acc_dt,\n        acc_gbt,\n        acc_catboost\n    ]})\nprint(\"---Reuglar Accuracy Scores---\")\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cv_models = pd.DataFrame({\n    'Model': ['KNN', 'Logistic Regression', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree', 'Gradient Boosting Trees',\n              'CatBoost'],\n    'Score': [\n        acc_cv_knn, \n        acc_cv_log,      \n        acc_cv_gaussian, \n        acc_cv_sgd, \n        acc_cv_linear_svc, \n        acc_cv_dt,\n        acc_cv_gbt,\n        acc_cv_catboost\n    ]})\nprint('---Cross-validation Accuracy Scores---')\ncv_models.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the tables, the CatBoost model had the best results. Getting just under 82% is pretty good considering guessing would result in about 50% accuracy (0 or 1).\n\nWe'll pay more attention to the cross-validation figure.\n\nCross-validation is more robust than just the `.fit()` models as it does multiple passes over the data instead of one.\n\nBecause the CatBoost model got the best results, we'll use it for the next steps.\n\n**Challenge:** How could you improve the CatBoost model?"},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance\nWhich features of the best model were most important for making predictions?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Feature Importance\ndef feature_importance(model, data):\n    \"\"\"\n    Function to show which features are most important in the model.\n    ::param_model:: Which model to use?\n    ::param_data:: What data to use?\n    \"\"\"\n    fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': data.columns})\n    fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\n    _ = fea_imp.plot(kind='barh', x='col', y='imp', figsize=(20, 10))\n    return fea_imp\n    #plt.savefig('catboost_feature_importance.png') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot the feature importance scores\nfeature_importance(catboost_model, X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Why would you want feature importance?\n\nFeatrue importance shows how much each feature contributed to the model.\n\nYou could take this information and remove features which don't contribute much to reduce dimenstionality (and save compute).\n\nYou could improve features which don't offer much to the overall model.\n\nOr you could improve features which offer more to the model. In this case, there aren't many ways you could improve sex as it's already a binary.\n\nFeature importance figures also show people who may not be familiar with the problem what features of their data are most important when it comes to making predictions with machine learning models."},{"metadata":{},"cell_type":"markdown","source":"## Precision and Recall\n\nPrecision and recall are two metrics which are used for cases where you have have an imbalanced classification problem.\n\nFor example, you may have 100,000 people and only 1 of them gets a certain disease. If your model predicts that all people don't have the disease, it only misses 1 in 100,000 so its accuracy is 99.999%. But this isn't really helpful.\n\nThis is where precision an recall come in.\n\n**Recall** = a metric which measures a models ability to find all the relevant cases in a dataset.\n\nRecall would be the models ability to find the 1 person in 100,000 who has the disease.\n\n**Precision** = a metric which measures a models ability to correctly identify only relevant instances.\n\nIn our example, Precision would be if the model found the 1 person who had the disease, did they actually have the disease.\n\nCombining the precision and recall, gives an **F1 score.**\n\nThese metrics will all fall between 0 and 1, with a higher value being better.\n\nAlthough, they don't necessarily need to come into play for our Titantic problem, they're worth remembering for your future work."},{"metadata":{"trusted":false},"cell_type":"code","source":"metrics = ['Precision', 'Recall', 'F1', 'AUC']\n\neval_metrics = catboost_model.eval_metrics(train_pool,\n                                           metrics=metrics,\n                                           plot=True)\n\nfor metric in metrics:\n    print(str(metric)+\": {}\".format(np.mean(eval_metrics[metric])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall is low, this means there's a higher amount of false negatives (predicting Did not survive when it was actually Survived).\n\nPrecision is higher therefore there's less false positives (predicting Survived, when it was actually Did not survive).\n\n**Challenge:** What are some ways to visualise precision and recall? \n*Hint:* You may want to look into what a confusion matrix is, you can find much more information in this blog post: [Beyond Accuracy: Precision and Recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)"},{"metadata":{},"cell_type":"markdown","source":"## Submission\nLet's use the model with the highest cross-validation accuracy score to make a prediction on the test dataset and then submit our predictions to Kaggle."},{"metadata":{},"cell_type":"markdown","source":"We want to make predictions on the same kind of columnns our model is trained on.\n\nSo we have to select the subset of right columns of the `test` dateframe, encode them and make a prediciton with our model."},{"metadata":{"trusted":false},"cell_type":"code","source":"# We need our test dataframe to look like this one\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Our test dataframe has some columns our model hasn't been trained on\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# One hot encode the columns in the test data frame (like X_train)\ntest_embarked_one_hot = pd.get_dummies(test['Embarked'], \n                                       prefix='embarked')\n\ntest_sex_one_hot = pd.get_dummies(test['Sex'], \n                                prefix='sex')\n\ntest_plcass_one_hot = pd.get_dummies(test['Pclass'], \n                                   prefix='pclass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Combine the test one hot encoded columns with test\ntest = pd.concat([test, \n                  test_embarked_one_hot, \n                  test_sex_one_hot, \n                  test_plcass_one_hot], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's look at test, it should have one hot encoded columns now\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns in `test` have been converted to the same format at `df_con_enc`. Now we can make predictions on the `test` dataframe columns we built a model on.\n\nWe can find the columns we made predictions on with `X_train.columns`."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a list of columns to be used for the predictions\nwanted_test_columns = X_train.columns\nwanted_test_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Make a prediction using the CatBoost model on the wanted columns\npredictions = catboost_model.predict(test[wanted_test_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Our predictions array is comprised of 0's and 1's (Survived or Did Not Survive)\npredictions[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a submisison dataframe and append the relevant columns\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = predictions # our model predictions on the test dataset\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# What does our submission have to look like?\ngender_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need our `submission` dataframe to look like the `gender_submisison` dataframe, so we'll turn the `Survived` column into integers."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's convert our submission dataframe 'Survived' column to ints\nsubmission['Survived'] = submission['Survived'].astype(int)\nprint('Converted Survived column to integers.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# How does our submission dataframe look?\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Are our test and submission dataframes the same length?\nif len(submission) == len(test):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert submisison dataframe to csv for submission to csv \n# for Kaggle submisison\nsubmission.to_csv('../catboost_submission.csv', index=False)\nprint('Submission CSV is ready!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Check the submission csv to make sure it's in the right format\nsubmissions_check = pd.read_csv(\"../catboost_submission.csv\")\nsubmissions_check.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now submit your .csv to Kaggle! \n\nhttps://www.kaggle.com/c/titanic/submit"},{"metadata":{},"cell_type":"markdown","source":"## Possible Extensions\n\nThese are all possible options to improve this pipeline. I'd suggest starting with the feature engineering (improving and manipulating the existing data) first.\n\n* What can you do with the `Age` feature?\n    * How would fill up all the missing values?\n    * You may want to look into the `interpolate()` function of Pandas for this\n<br>\n<br>\n2. What can you do with the `Name` feature?\n    * What titles did the passengers have? Did this influence their survival?\n<br>\n<br>\n3. What can you do with the `Cabin` feature?\n    * Is there a way to see whether they had a cabin or not?\n<br>\n<br>\n4. Can you combine the `SibSp` and `Parch` features to see if the person was alone or not?\n<br>\n<br>\n5. Could you do a PCA/feature analysis to see what features are more important than others?\n    * Does removing the less important model features improve the model?\n<br>\n<br>\n7. The models take a bunch of hyperparameters but we've mostly used the default settings, is there a way to find which hyperparameters are best to use?\n    * Tip: Check out the `CatBoost` with Python tutorial and the [hyperopt library](https://github.com/hyperopt/hyperopt) to see if you can improve the CatBoost model\n\n    "},{"metadata":{},"cell_type":"markdown","source":"## References and Learn More\n\n* [Sklearn Classification Notebook by Daniel Furasso](https://github.com/dformoso/sklearn-classification/blob/master/Data%20Science%20Workbook%20-%20Census%20Income%20Dataset.ipynb) - Daniel has done some epic work showing how you can take a bigger dataset, clean it up and perform some similar classification work from scratch. It would be a great next step after going through this one.\n<br>\n\n* [Encoding categorical features in Python blog post by Practical Python Business](http://pbpython.com/categorical-encoding.html) - this blog post sheds some great light on how to deal with categorical features in Python. The rest of the website contains plenty more great information for using Python in a business environment.\n<br>\n\n* [CatBoost Python tutorial on GitHub](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb) - the tutorial is based on the Titanic Dataset and has some great tricks to improve the results in this notebook.\n<br>\n\n* [Shap library](https://github.com/slundberg/shap) - a great (and beautiful) alternative to viewing feature importance. Can you use this to improve on the feature importance graphics?"},{"metadata":{},"cell_type":"markdown","source":"# THANKYOU\nKeep learning,\n\nFaraz\n\nfarazshaikh66@gmail.com"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}